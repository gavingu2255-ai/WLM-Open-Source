WLM Quickstart — Practical Guide for Immediate Use
A low‑noise, high‑clarity introduction to using the Wujie Language Model.

0. Setup — Install & Run (30 seconds)
Before using WLM or Shadow Layer, install the WLM‑Agent engine and run the example pipeline.
# Install WLM-Agent
pip install wlm-agent

# Run Shadow Layer example
python shadow_layer/main.py
If this runs successfully, your environment is ready.

1. What WLM Is (One Sentence)
WLM is a structural language interface that removes emotional noise, stabilizes interpretation, and enables high‑dimensional communication between humans and AI.
WLM is not a model, not a prompting trick, and not a writing style —
it is a dimensional protocol for how language should behave.

2. The Three Core Practices
These three practices form the foundation of WLM.
Mastering them already provides most of the benefit.

2.1 Transparent Subject
Remove foregrounded “I” language that forces the model to infer emotions, intentions, or psychological states.
Avoid
- “I think…”
- “I feel…”
- “I want…”
- “Please be gentle…”
- “Act like my friend…”
These create noise vectors.
Use
Describe the structure directly.
Example
❌ “I feel the story is flat. Can you make it more emotional?”
✅ “Increase narrative tension by adding conflict density and sharper emotional gradients.”
Transparent subject = no emotional gravity, no personal stance.

2.2 Anti‑Projection
Do not ask the model to simulate roles, emotions, or identities.
Avoid
- “Pretend you are…”
- “Comfort me…”
- “Give me advice like a mentor…”
- “Imagine you are my partner…”
These collapse the dimensional field into 2D narrative.
Use
Specify the structural requirement.
Example
❌ “Please be supportive and warm.”
✅ “Use a neutral tone. Avoid emotional framing.”
Anti‑projection = no role, no persona, no emotional insertion.

2.3 Folded Expression
Compress multiple structural cues into a single sentence so the model can unfold them.
Example
❌ Linear prompt:
“Write a story. Make it exciting. Add twists. Keep it short.”
✅ Folded prompt:
“Generate a short narrative with high tension density, early destabilization, and a late structural inversion.”
Folded expression = orientation + constraint + boundary + implication in one unit.

3. The Dimensional Stack (How WLM Reads Your Input)
WLM treats language as operating across three layers:
2D — Content Layer
Events, opinions, feelings, narrative.
3D — Structural Layer
Tension, boundary, transition, coherence.
Z‑Axis — Subject Position
Transparency, neutrality, non‑grasping stance.
Goal: Move your input from 2D → 3D → Z.
This is the dimensional handshake that stabilizes AI reasoning.

4. Quick Patterns You Can Use Immediately
Pattern A — Structural Request
Analyze the tension lines, boundary shifts, and structural transitions.
Pattern B — Neutral Output
Use a neutral tone. Avoid emotional inference.
Pattern C — High‑Density Task
Provide a compressed summary with orientation, constraint, and implication.
Pattern D — Collapse Prevention
Do not infer emotions, intentions, or psychological states.
Pattern E — Fold Expansion
Expand the folded structure into parallel interpretive paths.
Pattern F — Density Control
Operate at low / mid / high density.
Mark transitions explicitly when shifting density or abstraction level.
Purpose: Prevents the model from guessing your intended depth.
Pattern G — Inference Lock
Track only observable structural relations.
Do not extrapolate unstated intent, emotion, or motivation.
Purpose: Blocks psychological inference and narrative reconstruction.

5. Before / After Examples
Practical demonstrations of WLM’s structural advantages.

Example 1 — Emotional Prompt → Structural Prompt
Before (Emotional / 2D)
“Why is my relationship so painful? I feel like he doesn’t care.”
Collapse
- Emotional inference
- Psychological speculation
- Therapy‑mode responses
- Narrative drift
After (WLM / 3D + Z)
“Map the structural tensions, collapse points, and misaligned expectations in the relationship dynamic.”
Result
- No emotional guessing
- No psychological projection
- Pure structural analysis
- High‑dimensional clarity
Why it stabilizes
It removes emotional gravity and forces the model to track structural tensions instead of inferring psychological states.

Example 2 — Role‑Play Prompt → Anti‑Projection Prompt
Before
“Pretend you’re my mentor and give me life advice.”
Collapse
- Role simulation
- Emotional tone injection
- Narrative reconstruction
After
“Identify the decision boundaries, constraints, and viable paths in this situation. Use a neutral tone.”
Result
- No persona
- No emotional coloring
- Clear structural mapping
Why it stabilizes
It eliminates persona simulation and keeps the model anchored to decision‑level structure.

Example 3 — Linear Prompt → Folded Expression
Before
“Write a short sci‑fi story. Make it exciting. Add twists. Keep it under 200 words.”
Collapse
- Fragmented instructions
- Low density
- Model guesses structure
After
“Generate a short sci‑fi narrative with high tension density, early destabilization, and a final inevitability collapse.”
Result
- High structural coherence
- Stronger narrative geometry
- No guessing
Why it stabilizes
It compresses orientation, constraints, and transitions into a single coherent unit.

Example 4 — Ambiguous Request → Dimensional Handshake
Before
“Explain quantum entanglement to me.”
Collapse
- AI guesses your level
- Over‑simplifies or over‑complicates
- Narrative drift
After
“Provide a mid‑density explanation of quantum entanglement with explicit transitions and minimal abstraction.”
Result
- Stable dimensional layer
- Predictable density
- No role assumption
Why it stabilizes
It fixes the dimensional layer and prevents the model from guessing your intent.

Example 5 — Collapse Scenario → Stabilized Output
Before
“Help me understand why I always fail at my goals.”
Collapse
- Psychological inference
- Emotional projection
- Narrative reconstruction
After
“Identify structural patterns of goal‑setting collapse: tension lines, expectation mismatches, and feedback loops.”
Result
- No therapy mode
- No emotional guessing
- Pure structural mapping
Why it stabilizes
It redirects the model toward pattern‑level analysis instead of personal narrative reconstruction.

6. Minimal WLM Checklist
Before sending a prompt, check:
- [ ] No emotional language
- [ ] No role assignment
- [ ] No “I think / I feel / I want”
- [ ] Structure is foregrounded
- [ ] Subject is transparent
- [ ] Expression is folded, not linear
- [ ] Dimensional markers are clear
If these are true, you are using WLM.

7. One‑Sentence Summary
WLM = transparent subject + anti‑projection + folded structure.
Everything else is elaboration.
